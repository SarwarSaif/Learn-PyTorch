{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOjbZmv+G+xAB47f56gbOLC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SarwarSaif/Learn-PyTorch/blob/main/Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxKCLwG6LD9y"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZ21Nf1YLJes"
      },
      "source": [
        "> Steps for Logistic Regression:\n",
        "> 1. Design model (input, output size, forward pass)\n",
        "> 2. Construct loss and optimizer\n",
        "> 3. Training loop\n",
        ">  - forward pass: compute prediction\n",
        ">  - backward pass: gradients\n",
        ">  - update weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXcdqR8eK-Vw"
      },
      "source": [
        "# Import Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSsvBdjGMRFL",
        "outputId": "d33869b8-25f1-4ceb-844f-e2eb1078d3fb"
      },
      "source": [
        "# (1) Prepare our dataset\n",
        "breast_cancer_dataset = datasets.load_breast_cancer()\n",
        "X, y = breast_cancer_dataset.data, breast_cancer_dataset.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(f\"No of samples = {n_samples}, and features = {n_features}\")\n",
        "\n",
        "# Split our dataset\n",
        "X_train_np, X_test_np, y_train_np, y_test_np = train_test_split(X, y, test_size=0.2, random_state=1200)\n",
        "print(f'Shape of Trainset: (X, y) = {X_train_np.shape, y_train_np.shape}; Testset: (X, y) = {X_test_np.shape, y_test_np.shape}')\n",
        "\n",
        "# Scale our features so that our dataset has zero mean\n",
        "sc = StandardScaler()\n",
        "X_train_np = sc.fit_transform(X_train_np)\n",
        "X_test_np = sc.fit_transform(X_test_np)\n",
        "\n",
        "# Convert numpy to tensors\n",
        "X_train = torch.from_numpy(X_train_np.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test_np.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train_np.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test_np.astype(np.float32))\n",
        "# Reshape y into column vector\n",
        "y_train = y_train.view(y_train.shape[0], 1)\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "# (2) Create model\n",
        "# Incase of Logistic Regression Output is Categorical ccompared to Linear Regressions Continuous value\n",
        "# So Sigmoid activation function will be used here to convert the continuous predictions into categorical features\n",
        "# Linear Regression:            f = wx + b \n",
        "# Logistic Regression: sigmoid(f) = sigmoid(wx + b)\n",
        "class LogisticRegression(nn.Module):\n",
        "\n",
        "  def __init__(self, n_input_features):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear = nn.Linear(n_input_features, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y_pred = torch.sigmoid(self.linear(x))\n",
        "    return y_pred\n",
        "\n",
        "model = LogisticRegression(n_features)\n",
        "\n",
        "# (3) Set loss and optimizer\n",
        "learning_rate = 0.1\n",
        "loss = nn.BCELoss() # Binary Cross-entropy loss as the output is categorical and binary\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "# (4) Training Loop\n",
        "num_epochs = 1000\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  # forward pass and loss\n",
        "  y_pred = model(X_train)\n",
        "  l = loss(y_pred, y_train)\n",
        "\n",
        "  # backward pass\n",
        "  l.backward() # claculate gradients\n",
        "\n",
        "  # update \n",
        "  optimizer.step() # update weights\n",
        "  optimizer.zero_grad() # clear weights\n",
        "\n",
        "  if (epoch+1) % 50 == 0:\n",
        "    [w, b] = model.parameters() # unpack weights and bias\n",
        "    print(f\"epoch {epoch+1}: w = {w[0][0].item(): 0.3f}, loss = {l: 0.8f}\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No of samples = 569, and features = 30\n",
            "Shape of Trainset: (X, y) = ((455, 30), (455,)); Testset: (X, y) = ((114, 30), (114,))\n",
            "epoch 50: w = -0.269, loss =  0.13707282\n",
            "epoch 100: w = -0.332, loss =  0.10979845\n",
            "epoch 150: w = -0.368, loss =  0.09789727\n",
            "epoch 200: w = -0.392, loss =  0.09085508\n",
            "epoch 250: w = -0.409, loss =  0.08607253\n",
            "epoch 300: w = -0.422, loss =  0.08254970\n",
            "epoch 350: w = -0.432, loss =  0.07981084\n",
            "epoch 400: w = -0.440, loss =  0.07759820\n",
            "epoch 450: w = -0.446, loss =  0.07575889\n",
            "epoch 500: w = -0.450, loss =  0.07419591\n",
            "epoch 550: w = -0.454, loss =  0.07284445\n",
            "epoch 600: w = -0.456, loss =  0.07165930\n",
            "epoch 650: w = -0.458, loss =  0.07060780\n",
            "epoch 700: w = -0.459, loss =  0.06966572\n",
            "epoch 750: w = -0.459, loss =  0.06881467\n",
            "epoch 800: w = -0.459, loss =  0.06804029\n",
            "epoch 850: w = -0.459, loss =  0.06733124\n",
            "epoch 900: w = -0.458, loss =  0.06667849\n",
            "epoch 950: w = -0.457, loss =  0.06607457\n",
            "epoch 1000: w = -0.456, loss =  0.06551351\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CW6i9G3HNHdi",
        "outputId": "2bf5ba00-2cc1-4da4-d445-7a0de23b920d"
      },
      "source": [
        "# Calculate accuracy\n",
        "def get_acc(y, y_hat):\n",
        "  if y_hat is None:\n",
        "    return\n",
        "  return y_hat.eq(y).sum() / float(y.shape[0])\n",
        "\n",
        "with torch.no_grad():\n",
        "  y_pred = model(X_test)\n",
        "  y_pred_class = y_pred.round()\n",
        "  acc = get_acc(y_test, y_pred_class)\n",
        "print(f\"accuracy = {acc}\")\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy = 0.9122806787490845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH5eTbQmY3_U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
